[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,170 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,173 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,173 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,174 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,175 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,177 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2364] 2026-01-02 17:07:43,395 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:763] 2026-01-02 17:07:43,397 >> loading configuration file C:/models/Llama-3.1-8B-Instruct\config.json
[INFO|configuration_utils.py:839] 2026-01-02 17:07:43,399 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,401 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,401 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,401 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,402 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,402 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2093] 2026-01-02 17:07:43,402 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2364] 2026-01-02 17:07:43,614 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Converting format of dataset:   0%|          | 0/5672 [00:00<?, ? examples/s]Converting format of dataset:  71%|#######   | 4000/5672 [00:00<00:00, 37205.23 examples/s]Converting format of dataset: 100%|##########| 5672/5672 [00:00<00:00, 33528.52 examples/s]
Converting format of dataset:   0%|          | 0/630 [00:00<?, ? examples/s]Converting format of dataset: 100%|##########| 630/630 [00:00<00:00, 21599.09 examples/s]
Running tokenizer on dataset:   0%|          | 0/5672 [00:00<?, ? examples/s]Running tokenizer on dataset:  18%|#7        | 1000/5672 [00:01<00:09, 507.83 examples/s]Running tokenizer on dataset:  35%|###5      | 2000/5672 [00:04<00:07, 478.94 examples/s]Running tokenizer on dataset:  53%|#####2    | 3000/5672 [00:06<00:05, 488.14 examples/s]Running tokenizer on dataset:  71%|#######   | 4000/5672 [00:08<00:03, 490.74 examples/s]Running tokenizer on dataset:  88%|########8 | 5000/5672 [00:10<00:01, 492.47 examples/s]Running tokenizer on dataset: 100%|##########| 5672/5672 [00:11<00:00, 493.41 examples/s]Running tokenizer on dataset: 100%|##########| 5672/5672 [00:11<00:00, 489.96 examples/s]
Running tokenizer on dataset:   0%|          | 0/630 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|##########| 630/630 [00:01<00:00, 502.52 examples/s]Running tokenizer on dataset: 100%|##########| 630/630 [00:01<00:00, 490.24 examples/s]
[INFO|configuration_utils.py:763] 2026-01-02 17:07:57,779 >> loading configuration file C:/models/Llama-3.1-8B-Instruct\config.json
[INFO|configuration_utils.py:839] 2026-01-02 17:07:57,780 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "use_cache": true,
  "vocab_size": 128256
}

[WARNING|logging.py:328] 2026-01-02 17:07:57,974 >> `torch_dtype` is deprecated! Use `dtype` instead!
[INFO|modeling_utils.py:1169] 2026-01-02 17:07:57,975 >> loading weights file C:/models/Llama-3.1-8B-Instruct\model.safetensors.index.json
[INFO|modeling_utils.py:1243] 2026-01-02 17:07:57,975 >> Will use dtype=torch.bfloat16 as defined in model's config object
[INFO|modeling_utils.py:2341] 2026-01-02 17:07:57,975 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:986] 2026-01-02 17:07:57,977 >> Generate config GenerationConfig {
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "use_cache": false
}

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:02<00:06,  2.27s/it]Loading checkpoint shards:  50%|#####     | 2/4 [00:04<00:04,  2.10s/it]Loading checkpoint shards:  75%|#######5  | 3/4 [00:06<00:02,  2.09s/it]Loading checkpoint shards: 100%|##########| 4/4 [00:06<00:00,  1.45s/it]Loading checkpoint shards: 100%|##########| 4/4 [00:06<00:00,  1.70s/it]
[INFO|configuration_utils.py:939] 2026-01-02 17:08:04,839 >> loading configuration file C:/models/Llama-3.1-8B-Instruct\generation_config.json
[INFO|configuration_utils.py:986] 2026-01-02 17:08:04,839 >> Generate config GenerationConfig {
  "bos_token_id": 128000,
  "do_sample": true,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "temperature": 0.6,
  "top_p": 0.9
}

[INFO|dynamic_module_utils.py:423] 2026-01-02 17:08:04,840 >> Could not locate the custom_generate/generate.py inside C:/models/Llama-3.1-8B-Instruct.
[WARNING|trainer.py:906] 2026-01-02 17:08:05,774 >> The model is already on multiple devices. Skipping the move to device specified in `args`.
[INFO|trainer.py:749] 2026-01-02 17:08:05,778 >> Using auto half precision backend
[WARNING|trainer.py:982] 2026-01-02 17:08:05,779 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
[INFO|trainer.py:2519] 2026-01-02 17:08:06,004 >> ***** Running training *****
[INFO|trainer.py:2520] 2026-01-02 17:08:06,015 >>   Num examples = 5,672
[INFO|trainer.py:2521] 2026-01-02 17:08:06,015 >>   Num Epochs = 2
[INFO|trainer.py:2522] 2026-01-02 17:08:06,015 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2525] 2026-01-02 17:08:06,015 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:2526] 2026-01-02 17:08:06,015 >>   Gradient Accumulation steps = 16
[INFO|trainer.py:2527] 2026-01-02 17:08:06,015 >>   Total optimization steps = 710
[INFO|trainer.py:2528] 2026-01-02 17:08:06,018 >>   Number of trainable parameters = 83,886,080
  0%|          | 0/710 [00:00<?, ?it/s]  0%|          | 1/710 [00:18<3:41:46, 18.77s/it]  0%|          | 2/710 [00:36<3:30:54, 17.87s/it]  0%|          | 3/710 [00:54<3:32:13, 18.01s/it]  1%|          | 4/710 [01:12<3:33:39, 18.16s/it]  1%|          | 5/710 [01:30<3:33:12, 18.15s/it]  1%|          | 6/710 [01:49<3:34:40, 18.30s/it]  1%|          | 7/710 [02:07<3:32:34, 18.14s/it]  1%|1         | 8/710 [02:24<3:31:09, 18.05s/it]  1%|1         | 9/710 [02:43<3:32:32, 18.19s/it]  1%|1         | 10/710 [03:02<3:34:08, 18.36s/it]                                                    1%|1         | 10/710 [03:02<3:34:08, 18.36s/it]  2%|1         | 11/710 [03:20<3:34:55, 18.45s/it]  2%|1         | 12/710 [03:39<3:36:17, 18.59s/it]  2%|1         | 13/710 [03:59<3:38:57, 18.85s/it]  2%|1         | 14/710 [04:16<3:32:13, 18.29s/it]  2%|2         | 15/710 [04:35<3:34:36, 18.53s/it]  2%|2         | 16/710 [04:54<3:38:04, 18.85s/it]  2%|2         | 17/710 [05:13<3:35:44, 18.68s/it]  3%|2         | 18/710 [05:31<3:35:24, 18.68s/it]  3%|2         | 19/710 [05:50<3:35:40, 18.73s/it]  3%|2         | 20/710 [06:09<3:37:07, 18.88s/it]                                                    3%|2         | 20/710 [06:09<3:37:07, 18.88s/it]  3%|2         | 21/710 [06:29<3:40:36, 19.21s/it]  3%|3         | 22/710 [06:49<3:41:21, 19.31s/it]  3%|3         | 23/710 [07:07<3:35:28, 18.82s/it]  3%|3         | 24/710 [07:27<3:39:13, 19.17s/it]  4%|3         | 25/710 [07:45<3:37:00, 19.01s/it]  4%|3         | 26/710 [08:04<3:36:21, 18.98s/it]  4%|3         | 27/710 [08:23<3:34:37, 18.85s/it]  4%|3         | 28/710 [08:41<3:32:00, 18.65s/it]  4%|4         | 29/710 [08:58<3:28:01, 18.33s/it]  4%|4         | 30/710 [09:17<3:26:49, 18.25s/it]                                                    4%|4         | 30/710 [09:17<3:26:49, 18.25s/it]  4%|4         | 31/710 [09:35<3:27:30, 18.34s/it]  5%|4         | 32/710 [09:54<3:28:56, 18.49s/it]  5%|4         | 33/710 [10:11<3:24:47, 18.15s/it]  5%|4         | 34/710 [10:30<3:27:13, 18.39s/it]  5%|4         | 35/710 [10:49<3:27:30, 18.45s/it]  5%|5         | 36/710 [11:08<3:30:17, 18.72s/it]  5%|5         | 37/710 [11:26<3:28:04, 18.55s/it]  5%|5         | 38/710 [11:45<3:27:08, 18.49s/it]  5%|5         | 39/710 [12:04<3:28:24, 18.64s/it]  6%|5         | 40/710 [12:22<3:28:45, 18.69s/it]                                                    6%|5         | 40/710 [12:22<3:28:45, 18.69s/it]  6%|5         | 41/710 [12:40<3:24:28, 18.34s/it]  6%|5         | 42/710 [12:58<3:23:20, 18.26s/it]  6%|6         | 43/710 [13:17<3:23:54, 18.34s/it]  6%|6         | 44/710 [13:35<3:22:16, 18.22s/it]  6%|6         | 45/710 [13:53<3:21:36, 18.19s/it]  6%|6         | 46/710 [14:10<3:20:03, 18.08s/it]  7%|6         | 47/710 [14:30<3:23:26, 18.41s/it]  7%|6         | 48/710 [14:48<3:22:58, 18.40s/it]  7%|6         | 49/710 [15:06<3:21:00, 18.25s/it]  7%|7         | 50/710 [15:25<3:24:16, 18.57s/it]                                                    7%|7         | 50/710 [15:25<3:24:16, 18.57s/it]  7%|7         | 51/710 [15:43<3:22:45, 18.46s/it]  7%|7         | 52/710 [16:00<3:16:22, 17.91s/it]  7%|7         | 53/710 [16:18<3:16:21, 17.93s/it]  8%|7         | 54/710 [16:36<3:16:30, 17.97s/it]  8%|7         | 55/710 [16:54<3:16:35, 18.01s/it]  8%|7         | 56/710 [17:12<3:15:01, 17.89s/it]  8%|8         | 57/710 [17:31<3:18:45, 18.26s/it]  8%|8         | 58/710 [17:50<3:19:58, 18.40s/it]  8%|8         | 59/710 [18:07<3:16:30, 18.11s/it]  8%|8         | 60/710 [18:26<3:19:54, 18.45s/it]                                                    8%|8         | 60/710 [18:26<3:19:54, 18.45s/it]  9%|8         | 61/710 [18:46<3:22:13, 18.70s/it]  9%|8         | 62/710 [19:04<3:19:45, 18.50s/it]  9%|8         | 63/710 [19:22<3:17:59, 18.36s/it]  9%|9         | 64/710 [19:40<3:17:01, 18.30s/it]  9%|9         | 65/710 [19:59<3:18:02, 18.42s/it]  9%|9         | 66/710 [20:17<3:16:42, 18.33s/it]  9%|9         | 67/710 [20:36<3:18:04, 18.48s/it] 10%|9         | 68/710 [20:54<3:18:19, 18.54s/it] 10%|9         | 69/710 [21:13<3:18:27, 18.58s/it] 10%|9         | 70/710 [21:31<3:15:53, 18.37s/it]                                                   10%|9         | 70/710 [21:31<3:15:53, 18.37s/it] 10%|#         | 71/710 [21:49<3:15:26, 18.35s/it] 10%|#         | 72/710 [22:08<3:18:15, 18.65s/it] 10%|#         | 73/710 [22:27<3:17:50, 18.63s/it] 10%|#         | 74/710 [22:46<3:18:08, 18.69s/it] 11%|#         | 75/710 [23:05<3:19:08, 18.82s/it] 11%|#         | 76/710 [23:24<3:18:20, 18.77s/it] 11%|#         | 77/710 [23:42<3:16:55, 18.67s/it] 11%|#         | 78/710 [24:01<3:17:22, 18.74s/it] 11%|#1        | 79/710 [24:20<3:17:38, 18.79s/it] 11%|#1        | 80/710 [24:38<3:14:00, 18.48s/it]                                                   11%|#1        | 80/710 [24:38<3:14:00, 18.48s/it] 11%|#1        | 81/710 [24:56<3:13:39, 18.47s/it] 12%|#1        | 82/710 [25:13<3:09:34, 18.11s/it] 12%|#1        | 83/710 [25:32<3:10:29, 18.23s/it] 12%|#1        | 84/710 [25:50<3:10:28, 18.26s/it] 12%|#1        | 85/710 [26:08<3:09:36, 18.20s/it] 12%|#2        | 86/710 [26:26<3:09:30, 18.22s/it] 12%|#2        | 87/710 [26:45<3:09:47, 18.28s/it] 12%|#2        | 88/710 [27:04<3:10:51, 18.41s/it] 13%|#2        | 89/710 [27:23<3:12:36, 18.61s/it] 13%|#2        | 90/710 [27:42<3:14:10, 18.79s/it]                                                   13%|#2        | 90/710 [27:42<3:14:10, 18.79s/it] 13%|#2        | 91/710 [28:00<3:10:32, 18.47s/it] 13%|#2        | 92/710 [28:17<3:07:37, 18.22s/it] 13%|#3        | 93/710 [28:35<3:06:20, 18.12s/it] 13%|#3        | 94/710 [28:53<3:06:08, 18.13s/it] 13%|#3        | 95/710 [29:13<3:09:18, 18.47s/it] 14%|#3        | 96/710 [29:32<3:11:11, 18.68s/it] 14%|#3        | 97/710 [29:49<3:07:45, 18.38s/it] 14%|#3        | 98/710 [30:09<3:10:25, 18.67s/it] 14%|#3        | 99/710 [30:26<3:06:37, 18.33s/it] 14%|#4        | 100/710 [30:45<3:06:05, 18.30s/it]                                                    14%|#4        | 100/710 [30:45<3:06:05, 18.30s/it] 14%|#4        | 101/710 [31:03<3:05:16, 18.25s/it] 14%|#4        | 102/710 [31:21<3:05:45, 18.33s/it] 15%|#4        | 103/710 [31:40<3:06:46, 18.46s/it] 15%|#4        | 104/710 [31:57<3:02:39, 18.09s/it] 15%|#4        | 105/710 [32:15<3:01:16, 17.98s/it] 15%|#4        | 106/710 [32:33<3:02:44, 18.15s/it] 15%|#5        | 107/710 [32:52<3:04:12, 18.33s/it] 15%|#5        | 108/710 [33:11<3:05:57, 18.53s/it] 15%|#5        | 109/710 [33:30<3:07:28, 18.72s/it] 15%|#5        | 110/710 [33:49<3:07:21, 18.74s/it]                                                    15%|#5        | 110/710 [33:49<3:07:21, 18.74s/it] 16%|#5        | 111/710 [34:07<3:04:14, 18.46s/it] 16%|#5        | 112/710 [34:24<3:00:06, 18.07s/it] 16%|#5        | 113/710 [34:41<2:55:41, 17.66s/it] 16%|#6        | 114/710 [34:59<2:56:25, 17.76s/it] 16%|#6        | 115/710 [35:17<2:58:03, 17.96s/it] 16%|#6        | 116/710 [35:36<3:00:33, 18.24s/it] 16%|#6        | 117/710 [35:53<2:57:29, 17.96s/it] 17%|#6        | 118/710 [36:11<2:56:56, 17.93s/it] 17%|#6        | 119/710 [36:29<2:55:36, 17.83s/it] 17%|#6        | 120/710 [36:47<2:55:41, 17.87s/it]                                                    17%|#6        | 120/710 [36:47<2:55:41, 17.87s/it] 17%|#7        | 121/710 [37:05<2:55:20, 17.86s/it] 17%|#7        | 122/710 [37:23<2:56:50, 18.05s/it] 17%|#7        | 123/710 [37:42<2:57:45, 18.17s/it] 17%|#7        | 124/710 [37:59<2:56:05, 18.03s/it] 18%|#7        | 125/710 [38:17<2:55:55, 18.04s/it] 18%|#7        | 126/710 [38:36<2:58:46, 18.37s/it] 18%|#7        | 127/710 [38:54<2:56:10, 18.13s/it] 18%|#8        | 128/710 [39:12<2:56:35, 18.21s/it] 18%|#8        | 129/710 [39:30<2:55:28, 18.12s/it] 18%|#8        | 130/710 [39:49<2:57:40, 18.38s/it]                                                    18%|#8        | 130/710 [39:49<2:57:40, 18.38s/it] 18%|#8        | 131/710 [40:09<2:59:41, 18.62s/it] 19%|#8        | 132/710 [40:28<3:00:21, 18.72s/it] 19%|#8        | 133/710 [40:46<2:58:16, 18.54s/it] 19%|#8        | 134/710 [41:05<3:00:15, 18.78s/it] 19%|#9        | 135/710 [41:24<3:00:17, 18.81s/it] 19%|#9        | 136/710 [41:41<2:56:32, 18.45s/it] 19%|#9        | 137/710 [41:58<2:51:53, 18.00s/it] 19%|#9        | 138/710 [42:16<2:51:30, 17.99s/it] 20%|#9        | 139/710 [42:34<2:51:17, 18.00s/it] 20%|#9        | 140/710 [42:52<2:48:35, 17.75s/it]                                                    20%|#9        | 140/710 [42:52<2:48:35, 17.75s/it] 20%|#9        | 141/710 [43:10<2:50:18, 17.96s/it] 20%|##        | 142/710 [43:28<2:51:25, 18.11s/it] 20%|##        | 143/710 [43:46<2:50:11, 18.01s/it] 20%|##        | 144/710 [44:05<2:50:39, 18.09s/it] 20%|##        | 145/710 [44:23<2:50:10, 18.07s/it] 21%|##        | 146/710 [44:40<2:47:11, 17.79s/it] 21%|##        | 147/710 [44:57<2:46:20, 17.73s/it] 21%|##        | 148/710 [45:16<2:49:18, 18.07s/it] 21%|##        | 149/710 [45:34<2:49:43, 18.15s/it] 21%|##1       | 150/710 [45:54<2:52:14, 18.45s/it]                                                    21%|##1       | 150/710 [45:54<2:52:14, 18.45s/it] 21%|##1       | 151/710 [46:13<2:55:19, 18.82s/it] 21%|##1       | 152/710 [46:32<2:55:10, 18.84s/it] 22%|##1       | 153/710 [46:51<2:53:36, 18.70s/it] 22%|##1       | 154/710 [47:08<2:51:01, 18.46s/it] 22%|##1       | 155/710 [47:27<2:50:32, 18.44s/it] 22%|##1       | 156/710 [47:45<2:50:39, 18.48s/it] 22%|##2       | 157/710 [48:04<2:51:14, 18.58s/it] 22%|##2       | 158/710 [48:22<2:47:49, 18.24s/it] 22%|##2       | 159/710 [48:40<2:47:08, 18.20s/it] 23%|##2       | 160/710 [48:59<2:48:41, 18.40s/it]                                                    23%|##2       | 160/710 [48:59<2:48:41, 18.40s/it] 23%|##2       | 161/710 [49:17<2:47:29, 18.30s/it] 23%|##2       | 162/710 [49:35<2:46:47, 18.26s/it] 23%|##2       | 163/710 [49:53<2:47:10, 18.34s/it] 23%|##3       | 164/710 [50:13<2:49:19, 18.61s/it] 23%|##3       | 165/710 [50:30<2:45:40, 18.24s/it] 23%|##3       | 166/710 [50:48<2:44:22, 18.13s/it] 24%|##3       | 167/710 [51:07<2:47:21, 18.49s/it] 24%|##3       | 168/710 [51:25<2:46:23, 18.42s/it] 24%|##3       | 169/710 [51:44<2:47:14, 18.55s/it] 24%|##3       | 170/710 [52:03<2:47:21, 18.59s/it]                                                    24%|##3       | 170/710 [52:03<2:47:21, 18.59s/it] 24%|##4       | 171/710 [52:22<2:46:50, 18.57s/it] 24%|##4       | 172/710 [52:40<2:45:08, 18.42s/it] 24%|##4       | 173/710 [52:57<2:42:32, 18.16s/it] 25%|##4       | 174/710 [53:16<2:43:15, 18.28s/it] 25%|##4       | 175/710 [53:34<2:41:55, 18.16s/it] 25%|##4       | 176/710 [53:53<2:45:43, 18.62s/it] 25%|##4       | 177/710 [54:12<2:46:34, 18.75s/it] 25%|##5       | 178/710 [54:31<2:46:17, 18.76s/it] 25%|##5       | 179/710 [54:51<2:49:05, 19.11s/it] 25%|##5       | 180/710 [55:10<2:49:03, 19.14s/it]                                                    25%|##5       | 180/710 [55:10<2:49:03, 19.14s/it] 25%|##5       | 181/710 [55:28<2:45:17, 18.75s/it] 26%|##5       | 182/710 [55:48<2:48:52, 19.19s/it] 26%|##5       | 183/710 [56:08<2:50:42, 19.44s/it] 26%|##5       | 184/710 [56:25<2:44:00, 18.71s/it] 26%|##6       | 185/710 [56:45<2:45:09, 18.88s/it] 26%|##6       | 186/710 [57:04<2:45:04, 18.90s/it] 26%|##6       | 187/710 [57:22<2:42:16, 18.62s/it] 26%|##6       | 188/710 [57:40<2:41:41, 18.58s/it] 27%|##6       | 189/710 [57:58<2:40:19, 18.46s/it] 27%|##6       | 190/710 [58:16<2:38:55, 18.34s/it]                                                    27%|##6       | 190/710 [58:16<2:38:55, 18.34s/it] 27%|##6       | 191/710 [58:36<2:41:58, 18.73s/it] 27%|##7       | 192/710 [58:54<2:41:06, 18.66s/it] 27%|##7       | 193/710 [59:12<2:38:52, 18.44s/it] 27%|##7       | 194/710 [59:30<2:36:29, 18.20s/it] 27%|##7       | 195/710 [59:48<2:36:40, 18.25s/it] 28%|##7       | 196/710 [1:00:06<2:35:11, 18.12s/it] 28%|##7       | 197/710 [1:00:25<2:37:38, 18.44s/it] 28%|##7       | 198/710 [1:00:43<2:35:01, 18.17s/it] 28%|##8       | 199/710 [1:01:02<2:38:04, 18.56s/it] 28%|##8       | 200/710 [1:01:21<2:38:12, 18.61s/it]                                                      28%|##8       | 200/710 [1:01:21<2:38:12, 18.61s/it][INFO|trainer.py:4309] 2026-01-02 18:09:27,620 >> Saving model checkpoint to lora/output_l4_lora\checkpoint-200
[INFO|configuration_utils.py:763] 2026-01-02 18:09:27,643 >> loading configuration file C:/models/Llama-3.1-8B-Instruct\config.json
[INFO|configuration_utils.py:839] 2026-01-02 18:09:27,644 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2421] 2026-01-02 18:09:27,840 >> chat template saved in lora/output_l4_lora\checkpoint-200\chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2026-01-02 18:09:27,842 >> tokenizer config file saved in lora/output_l4_lora\checkpoint-200\tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2026-01-02 18:09:27,842 >> Special tokens file saved in lora/output_l4_lora\checkpoint-200\special_tokens_map.json
 28%|##8       | 201/710 [1:01:40<2:39:27, 18.80s/it] 28%|##8       | 202/710 [1:01:58<2:35:47, 18.40s/it] 29%|##8       | 203/710 [1:02:17<2:37:01, 18.58s/it] 29%|##8       | 204/710 [1:02:36<2:37:28, 18.67s/it] 29%|##8       | 205/710 [1:02:54<2:37:13, 18.68s/it] 29%|##9       | 206/710 [1:03:13<2:37:59, 18.81s/it] 29%|##9       | 207/710 [1:03:33<2:39:56, 19.08s/it] 29%|##9       | 208/710 [1:03:51<2:37:35, 18.84s/it] 29%|##9       | 209/710 [1:04:09<2:34:24, 18.49s/it] 30%|##9       | 210/710 [1:04:27<2:32:18, 18.28s/it]                                                      30%|##9       | 210/710 [1:04:27<2:32:18, 18.28s/it] 30%|##9       | 211/710 [1:04:45<2:32:03, 18.28s/it] 30%|##9       | 212/710 [1:05:04<2:32:25, 18.37s/it] 30%|###       | 213/710 [1:05:23<2:33:19, 18.51s/it] 30%|###       | 214/710 [1:05:41<2:32:43, 18.47s/it] 30%|###       | 215/710 [1:05:59<2:32:06, 18.44s/it] 30%|###       | 216/710 [1:06:18<2:31:24, 18.39s/it] 31%|###       | 217/710 [1:06:36<2:30:37, 18.33s/it] 31%|###       | 218/710 [1:06:54<2:29:45, 18.26s/it] 31%|###       | 219/710 [1:07:12<2:30:02, 18.34s/it] 31%|###       | 220/710 [1:07:30<2:27:06, 18.01s/it]                                                      31%|###       | 220/710 [1:07:30<2:27:06, 18.01s/it] 31%|###1      | 221/710 [1:07:49<2:29:39, 18.36s/it] 31%|###1      | 222/710 [1:08:08<2:30:38, 18.52s/it] 31%|###1      | 223/710 [1:08:26<2:30:03, 18.49s/it] 32%|###1      | 224/710 [1:08:44<2:29:16, 18.43s/it] 32%|###1      | 225/710 [1:09:04<2:31:13, 18.71s/it] 32%|###1      | 226/710 [1:09:23<2:32:15, 18.87s/it] 32%|###1      | 227/710 [1:09:40<2:28:08, 18.40s/it] 32%|###2      | 228/710 [1:10:00<2:30:03, 18.68s/it] 32%|###2      | 229/710 [1:10:18<2:29:03, 18.59s/it] 32%|###2      | 230/710 [1:10:37<2:28:55, 18.62s/it]                                                      32%|###2      | 230/710 [1:10:37<2:28:55, 18.62s/it] 33%|###2      | 231/710 [1:10:54<2:26:26, 18.34s/it] 33%|###2      | 232/710 [1:11:12<2:25:02, 18.21s/it] 33%|###2      | 233/710 [1:11:30<2:24:30, 18.18s/it] 33%|###2      | 234/710 [1:11:49<2:24:44, 18.24s/it] 33%|###3      | 235/710 [1:12:07<2:23:51, 18.17s/it] 33%|###3      | 236/710 [1:12:26<2:24:35, 18.30s/it] 33%|###3      | 237/710 [1:12:44<2:24:39, 18.35s/it] 34%|###3      | 238/710 [1:13:01<2:22:06, 18.06s/it] 34%|###3      | 239/710 [1:13:19<2:20:55, 17.95s/it] 34%|###3      | 240/710 [1:13:36<2:18:55, 17.74s/it]                                                      34%|###3      | 240/710 [1:13:36<2:18:55, 17.74s/it] 34%|###3      | 241/710 [1:13:54<2:19:09, 17.80s/it] 34%|###4      | 242/710 [1:14:14<2:23:20, 18.38s/it] 34%|###4      | 243/710 [1:14:32<2:22:11, 18.27s/it] 34%|###4      | 244/710 [1:14:50<2:20:36, 18.10s/it] 35%|###4      | 245/710 [1:15:07<2:17:26, 17.73s/it] 35%|###4      | 246/710 [1:15:25<2:18:53, 17.96s/it] 35%|###4      | 247/710 [1:15:45<2:22:26, 18.46s/it] 35%|###4      | 248/710 [1:16:03<2:21:38, 18.39s/it] 35%|###5      | 249/710 [1:16:21<2:20:38, 18.30s/it] 35%|###5      | 250/710 [1:16:39<2:20:35, 18.34s/it]                                                      35%|###5      | 250/710 [1:16:39<2:20:35, 18.34s/it] 35%|###5      | 251/710 [1:16:57<2:19:38, 18.25s/it] 35%|###5      | 252/710 [1:17:17<2:21:37, 18.55s/it] 36%|###5      | 253/710 [1:17:35<2:19:37, 18.33s/it] 36%|###5      | 254/710 [1:17:53<2:18:54, 18.28s/it] 36%|###5      | 255/710 [1:18:11<2:17:44, 18.16s/it] 36%|###6      | 256/710 [1:18:29<2:17:12, 18.13s/it] 36%|###6      | 257/710 [1:18:47<2:16:48, 18.12s/it] 36%|###6      | 258/710 [1:19:06<2:19:07, 18.47s/it] 36%|###6      | 259/710 [1:19:24<2:17:47, 18.33s/it] 37%|###6      | 260/710 [1:19:42<2:17:03, 18.27s/it]                                                      37%|###6      | 260/710 [1:19:42<2:17:03, 18.27s/it] 37%|###6      | 261/710 [1:20:00<2:15:49, 18.15s/it] 37%|###6      | 262/710 [1:20:19<2:17:04, 18.36s/it] 37%|###7      | 263/710 [1:20:37<2:16:52, 18.37s/it] 37%|###7      | 264/710 [1:20:56<2:17:49, 18.54s/it] 37%|###7      | 265/710 [1:21:15<2:18:57, 18.74s/it] 37%|###7      | 266/710 [1:21:35<2:19:29, 18.85s/it] 38%|###7      | 267/710 [1:21:52<2:16:38, 18.51s/it] 38%|###7      | 268/710 [1:22:11<2:15:53, 18.45s/it] 38%|###7      | 269/710 [1:22:28<2:12:19, 18.00s/it] 38%|###8      | 270/710 [1:22:46<2:13:49, 18.25s/it]                                                      38%|###8      | 270/710 [1:22:46<2:13:49, 18.25s/it] 38%|###8      | 271/710 [1:23:05<2:15:29, 18.52s/it] 38%|###8      | 272/710 [1:23:24<2:15:38, 18.58s/it] 38%|###8      | 273/710 [1:23:43<2:14:53, 18.52s/it] 39%|###8      | 274/710 [1:24:01<2:15:15, 18.61s/it] 39%|###8      | 275/710 [1:24:19<2:12:50, 18.32s/it] 39%|###8      | 276/710 [1:24:36<2:09:38, 17.92s/it] 39%|###9      | 277/710 [1:24:54<2:09:14, 17.91s/it] 39%|###9      | 278/710 [1:25:13<2:11:49, 18.31s/it] 39%|###9      | 279/710 [1:25:31<2:09:47, 18.07s/it] 39%|###9      | 280/710 [1:25:49<2:09:15, 18.04s/it]                                                      39%|###9      | 280/710 [1:25:49<2:09:15, 18.04s/it] 40%|###9      | 281/710 [1:26:07<2:09:13, 18.07s/it] 40%|###9      | 282/710 [1:26:26<2:10:32, 18.30s/it] 40%|###9      | 283/710 [1:26:43<2:08:03, 17.99s/it] 40%|####      | 284/710 [1:27:03<2:11:14, 18.49s/it] 40%|####      | 285/710 [1:27:20<2:08:10, 18.09s/it] 40%|####      | 286/710 [1:27:39<2:09:27, 18.32s/it] 40%|####      | 287/710 [1:27:57<2:09:33, 18.38s/it] 41%|####      | 288/710 [1:28:14<2:06:48, 18.03s/it] 41%|####      | 289/710 [1:28:33<2:08:52, 18.37s/it] 41%|####      | 290/710 [1:28:53<2:10:08, 18.59s/it]                                                      41%|####      | 290/710 [1:28:53<2:10:08, 18.59s/it] 41%|####      | 291/710 [1:29:10<2:08:23, 18.39s/it] 41%|####1     | 292/710 [1:29:27<2:04:55, 17.93s/it] 41%|####1     | 293/710 [1:29:46<2:06:44, 18.24s/it] 41%|####1     | 294/710 [1:30:05<2:07:56, 18.45s/it] 42%|####1     | 295/710 [1:30:24<2:07:44, 18.47s/it] 42%|####1     | 296/710 [1:30:42<2:06:34, 18.35s/it] 42%|####1     | 297/710 [1:31:00<2:05:42, 18.26s/it] 42%|####1     | 298/710 [1:31:18<2:05:59, 18.35s/it] 42%|####2     | 299/710 [1:31:37<2:06:26, 18.46s/it] 42%|####2     | 300/710 [1:31:55<2:04:20, 18.20s/it]                                                      42%|####2     | 300/710 [1:31:55<2:04:20, 18.20s/it] 42%|####2     | 301/710 [1:32:12<2:01:44, 17.86s/it] 43%|####2     | 302/710 [1:32:30<2:02:57, 18.08s/it] 43%|####2     | 303/710 [1:32:50<2:05:46, 18.54s/it] 43%|####2     | 304/710 [1:33:09<2:05:29, 18.54s/it] 43%|####2     | 305/710 [1:33:25<2:01:47, 18.04s/it] 43%|####3     | 306/710 [1:33:44<2:01:54, 18.11s/it] 43%|####3     | 307/710 [1:34:03<2:03:09, 18.34s/it] 43%|####3     | 308/710 [1:34:20<2:01:34, 18.14s/it] 44%|####3     | 309/710 [1:34:38<2:00:40, 18.06s/it] 44%|####3     | 310/710 [1:34:56<2:00:09, 18.02s/it]                                                      44%|####3     | 310/710 [1:34:56<2:00:09, 18.02s/it] 44%|####3     | 311/710 [1:35:14<1:59:30, 17.97s/it] 44%|####3     | 312/710 [1:35:32<2:00:20, 18.14s/it] 44%|####4     | 313/710 [1:35:50<1:59:18, 18.03s/it] 44%|####4     | 314/710 [1:36:08<1:58:57, 18.02s/it] 44%|####4     | 315/710 [1:36:28<2:01:32, 18.46s/it] 45%|####4     | 316/710 [1:36:45<1:58:00, 17.97s/it] 45%|####4     | 317/710 [1:37:04<2:00:59, 18.47s/it] 45%|####4     | 318/710 [1:37:22<1:59:56, 18.36s/it] 45%|####4     | 319/710 [1:37:40<1:59:06, 18.28s/it] 45%|####5     | 320/710 [1:37:59<1:58:45, 18.27s/it]                                                      45%|####5     | 320/710 [1:37:59<1:58:45, 18.27s/it] 45%|####5     | 321/710 [1:38:16<1:56:28, 17.97s/it] 45%|####5     | 322/710 [1:38:35<1:57:35, 18.19s/it] 45%|####5     | 323/710 [1:38:53<1:57:05, 18.15s/it] 46%|####5     | 324/710 [1:39:11<1:58:01, 18.35s/it] 46%|####5     | 325/710 [1:39:29<1:57:03, 18.24s/it] 46%|####5     | 326/710 [1:39:49<1:58:26, 18.51s/it] 46%|####6     | 327/710 [1:40:07<1:58:07, 18.50s/it] 46%|####6     | 328/710 [1:40:26<1:58:25, 18.60s/it] 46%|####6     | 329/710 [1:40:44<1:56:41, 18.38s/it] 46%|####6     | 330/710 [1:41:02<1:56:43, 18.43s/it]                                                      46%|####6     | 330/710 [1:41:02<1:56:43, 18.43s/it] 47%|####6     | 331/710 [1:41:18<1:50:57, 17.57s/it] 47%|####6     | 332/710 [1:41:36<1:51:36, 17.72s/it] 47%|####6     | 333/710 [1:41:54<1:51:53, 17.81s/it] 47%|####7     | 334/710 [1:42:12<1:52:32, 17.96s/it] 47%|####7     | 335/710 [1:42:30<1:52:41, 18.03s/it] 47%|####7     | 336/710 [1:42:49<1:52:28, 18.04s/it] 47%|####7     | 337/710 [1:43:06<1:50:52, 17.83s/it] 48%|####7     | 338/710 [1:43:24<1:50:57, 17.90s/it] 48%|####7     | 339/710 [1:43:43<1:52:26, 18.18s/it] 48%|####7     | 340/710 [1:44:01<1:52:05, 18.18s/it]                                                      48%|####7     | 340/710 [1:44:01<1:52:05, 18.18s/it] 48%|####8     | 341/710 [1:44:19<1:51:52, 18.19s/it] 48%|####8     | 342/710 [1:44:38<1:52:15, 18.30s/it] 48%|####8     | 343/710 [1:44:56<1:52:24, 18.38s/it] 48%|####8     | 344/710 [1:45:14<1:51:19, 18.25s/it] 49%|####8     | 345/710 [1:45:30<1:47:08, 17.61s/it] 49%|####8     | 346/710 [1:45:49<1:49:09, 17.99s/it] 49%|####8     | 347/710 [1:46:07<1:48:20, 17.91s/it] 49%|####9     | 348/710 [1:46:26<1:49:44, 18.19s/it] 49%|####9     | 349/710 [1:46:45<1:50:30, 18.37s/it] 49%|####9     | 350/710 [1:47:03<1:50:09, 18.36s/it]                                                      49%|####9     | 350/710 [1:47:03<1:50:09, 18.36s/it] 49%|####9     | 351/710 [1:47:22<1:51:32, 18.64s/it] 50%|####9     | 352/710 [1:47:41<1:50:53, 18.58s/it] 50%|####9     | 353/710 [1:47:59<1:50:19, 18.54s/it] 50%|####9     | 354/710 [1:48:17<1:49:44, 18.50s/it] 50%|#####     | 355/710 [1:48:27<1:32:41, 15.67s/it] 50%|#####     | 356/710 [1:48:44<1:35:12, 16.14s/it] 50%|#####     | 357/710 [1:49:01<1:37:22, 16.55s/it] 50%|#####     | 358/710 [1:49:21<1:41:55, 17.37s/it] 51%|#####     | 359/710 [1:49:39<1:43:58, 17.77s/it] 51%|#####     | 360/710 [1:49:58<1:45:25, 18.07s/it]                                                      51%|#####     | 360/710 [1:49:58<1:45:25, 18.07s/it] 51%|#####     | 361/710 [1:50:16<1:45:30, 18.14s/it] 51%|#####     | 362/710 [1:50:34<1:44:49, 18.07s/it] 51%|#####1    | 363/710 [1:50:51<1:42:16, 17.68s/it] 51%|#####1    | 364/710 [1:51:10<1:43:55, 18.02s/it] 51%|#####1    | 365/710 [1:51:28<1:44:18, 18.14s/it] 52%|#####1    | 366/710 [1:51:46<1:43:42, 18.09s/it] 52%|#####1    | 367/710 [1:52:05<1:43:44, 18.15s/it] 52%|#####1    | 368/710 [1:52:23<1:44:39, 18.36s/it] 52%|#####1    | 369/710 [1:52:42<1:43:53, 18.28s/it] 52%|#####2    | 370/710 [1:53:00<1:44:43, 18.48s/it]                                                      52%|#####2    | 370/710 [1:53:00<1:44:43, 18.48s/it] 52%|#####2    | 371/710 [1:53:18<1:43:01, 18.24s/it] 52%|#####2    | 372/710 [1:53:37<1:44:00, 18.46s/it] 53%|#####2    | 373/710 [1:53:55<1:42:29, 18.25s/it] 53%|#####2    | 374/710 [1:54:14<1:42:52, 18.37s/it] 53%|#####2    | 375/710 [1:54:32<1:42:31, 18.36s/it] 53%|#####2    | 376/710 [1:54:49<1:40:50, 18.11s/it] 53%|#####3    | 377/710 [1:55:09<1:42:29, 18.47s/it] 53%|#####3    | 378/710 [1:55:28<1:43:08, 18.64s/it] 53%|#####3    | 379/710 [1:55:46<1:42:22, 18.56s/it] 54%|#####3    | 380/710 [1:56:03<1:39:54, 18.17s/it]                                                      54%|#####3    | 380/710 [1:56:03<1:39:54, 18.17s/it] 54%|#####3    | 381/710 [1:56:22<1:40:55, 18.41s/it] 54%|#####3    | 382/710 [1:56:39<1:37:31, 17.84s/it] 54%|#####3    | 383/710 [1:56:58<1:39:11, 18.20s/it] 54%|#####4    | 384/710 [1:57:16<1:39:22, 18.29s/it] 54%|#####4    | 385/710 [1:57:34<1:38:39, 18.21s/it] 54%|#####4    | 386/710 [1:57:53<1:39:34, 18.44s/it] 55%|#####4    | 387/710 [1:58:10<1:37:06, 18.04s/it] 55%|#####4    | 388/710 [1:58:29<1:38:02, 18.27s/it] 55%|#####4    | 389/710 [1:58:47<1:37:25, 18.21s/it] 55%|#####4    | 390/710 [1:59:06<1:37:09, 18.22s/it]                                                      55%|#####4    | 390/710 [1:59:06<1:37:09, 18.22s/it] 55%|#####5    | 391/710 [1:59:24<1:36:58, 18.24s/it] 55%|#####5    | 392/710 [1:59:41<1:35:05, 17.94s/it] 55%|#####5    | 393/710 [2:00:01<1:37:41, 18.49s/it] 55%|#####5    | 394/710 [2:00:21<1:39:31, 18.90s/it] 56%|#####5    | 395/710 [2:00:40<1:39:59, 19.05s/it] 56%|#####5    | 396/710 [2:00:59<1:39:47, 19.07s/it] 56%|#####5    | 397/710 [2:01:18<1:39:29, 19.07s/it] 56%|#####6    | 398/710 [2:01:37<1:38:45, 18.99s/it] 56%|#####6    | 399/710 [2:01:57<1:39:39, 19.23s/it] 56%|#####6    | 400/710 [2:02:16<1:39:23, 19.24s/it]                                                      56%|#####6    | 400/710 [2:02:16<1:39:23, 19.24s/it][INFO|trainer.py:4309] 2026-01-02 19:10:22,694 >> Saving model checkpoint to lora/output_l4_lora\checkpoint-400
[INFO|configuration_utils.py:763] 2026-01-02 19:10:22,721 >> loading configuration file C:/models/Llama-3.1-8B-Instruct\config.json
[INFO|configuration_utils.py:839] 2026-01-02 19:10:22,722 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:10:22,907 >> chat template saved in lora/output_l4_lora\checkpoint-400\chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:10:22,911 >> tokenizer config file saved in lora/output_l4_lora\checkpoint-400\tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:10:22,911 >> Special tokens file saved in lora/output_l4_lora\checkpoint-400\special_tokens_map.json
 56%|#####6    | 401/710 [2:02:36<1:40:08, 19.45s/it] 57%|#####6    | 402/710 [2:02:56<1:40:06, 19.50s/it] 57%|#####6    | 403/710 [2:03:16<1:40:28, 19.64s/it] 57%|#####6    | 404/710 [2:03:35<1:39:07, 19.43s/it] 57%|#####7    | 405/710 [2:03:54<1:39:00, 19.48s/it] 57%|#####7    | 406/710 [2:04:12<1:36:23, 19.03s/it] 57%|#####7    | 407/710 [2:04:32<1:36:32, 19.12s/it] 57%|#####7    | 408/710 [2:04:50<1:35:28, 18.97s/it] 58%|#####7    | 409/710 [2:05:08<1:33:29, 18.63s/it] 58%|#####7    | 410/710 [2:05:26<1:32:32, 18.51s/it]                                                      58%|#####7    | 410/710 [2:05:26<1:32:32, 18.51s/it] 58%|#####7    | 411/710 [2:05:44<1:31:20, 18.33s/it] 58%|#####8    | 412/710 [2:06:03<1:32:31, 18.63s/it] 58%|#####8    | 413/710 [2:06:22<1:31:25, 18.47s/it] 58%|#####8    | 414/710 [2:06:40<1:31:17, 18.51s/it] 58%|#####8    | 415/710 [2:06:58<1:29:38, 18.23s/it] 59%|#####8    | 416/710 [2:07:16<1:29:17, 18.22s/it] 59%|#####8    | 417/710 [2:07:34<1:28:12, 18.06s/it] 59%|#####8    | 418/710 [2:07:51<1:26:15, 17.72s/it] 59%|#####9    | 419/710 [2:08:10<1:28:05, 18.16s/it] 59%|#####9    | 420/710 [2:08:28<1:27:32, 18.11s/it]                                                      59%|#####9    | 420/710 [2:08:28<1:27:32, 18.11s/it] 59%|#####9    | 421/710 [2:08:46<1:27:48, 18.23s/it] 59%|#####9    | 422/710 [2:09:05<1:28:20, 18.40s/it] 60%|#####9    | 423/710 [2:09:23<1:27:54, 18.38s/it] 60%|#####9    | 424/710 [2:09:42<1:27:38, 18.39s/it] 60%|#####9    | 425/710 [2:10:00<1:27:12, 18.36s/it] 60%|######    | 426/710 [2:10:19<1:27:06, 18.40s/it] 60%|######    | 427/710 [2:10:38<1:28:04, 18.67s/it] 60%|######    | 428/710 [2:10:56<1:26:45, 18.46s/it] 60%|######    | 429/710 [2:11:14<1:26:11, 18.40s/it] 61%|######    | 430/710 [2:11:32<1:24:52, 18.19s/it]                                                      61%|######    | 430/710 [2:11:32<1:24:52, 18.19s/it] 61%|######    | 431/710 [2:11:50<1:25:03, 18.29s/it] 61%|######    | 432/710 [2:12:07<1:22:38, 17.83s/it] 61%|######    | 433/710 [2:12:26<1:23:22, 18.06s/it] 61%|######1   | 434/710 [2:12:45<1:24:07, 18.29s/it] 61%|######1   | 435/710 [2:13:04<1:24:46, 18.49s/it] 61%|######1   | 436/710 [2:13:23<1:25:49, 18.80s/it] 62%|######1   | 437/710 [2:13:42<1:25:24, 18.77s/it] 62%|######1   | 438/710 [2:14:01<1:25:54, 18.95s/it] 62%|######1   | 439/710 [2:14:20<1:25:40, 18.97s/it] 62%|######1   | 440/710 [2:14:40<1:26:26, 19.21s/it]                                                      62%|######1   | 440/710 [2:14:40<1:26:26, 19.21s/it] 62%|######2   | 441/710 [2:14:58<1:24:28, 18.84s/it] 62%|######2   | 442/710 [2:15:16<1:22:54, 18.56s/it] 62%|######2   | 443/710 [2:15:35<1:23:14, 18.70s/it] 63%|######2   | 444/710 [2:15:52<1:21:23, 18.36s/it] 63%|######2   | 445/710 [2:16:10<1:20:23, 18.20s/it] 63%|######2   | 446/710 [2:16:28<1:19:34, 18.09s/it] 63%|######2   | 447/710 [2:16:48<1:21:38, 18.63s/it] 63%|######3   | 448/710 [2:17:08<1:22:38, 18.92s/it] 63%|######3   | 449/710 [2:17:26<1:21:20, 18.70s/it] 63%|######3   | 450/710 [2:17:46<1:22:31, 19.04s/it]                                                      63%|######3   | 450/710 [2:17:46<1:22:31, 19.04s/it] 64%|######3   | 451/710 [2:18:05<1:22:07, 19.02s/it] 64%|######3   | 452/710 [2:18:22<1:19:56, 18.59s/it] 64%|######3   | 453/710 [2:18:42<1:20:46, 18.86s/it] 64%|######3   | 454/710 [2:19:02<1:21:51, 19.18s/it] 64%|######4   | 455/710 [2:19:20<1:20:29, 18.94s/it] 64%|######4   | 456/710 [2:19:40<1:21:07, 19.17s/it] 64%|######4   | 457/710 [2:19:58<1:20:26, 19.08s/it] 65%|######4   | 458/710 [2:20:17<1:19:34, 18.95s/it] 65%|######4   | 459/710 [2:20:36<1:18:55, 18.87s/it] 65%|######4   | 460/710 [2:20:54<1:18:23, 18.82s/it]                                                      65%|######4   | 460/710 [2:20:54<1:18:23, 18.82s/it] 65%|######4   | 461/710 [2:21:13<1:17:52, 18.77s/it] 65%|######5   | 462/710 [2:21:32<1:17:51, 18.83s/it] 65%|######5   | 463/710 [2:21:51<1:17:38, 18.86s/it] 65%|######5   | 464/710 [2:22:10<1:17:19, 18.86s/it] 65%|######5   | 465/710 [2:22:30<1:18:20, 19.19s/it] 66%|######5   | 466/710 [2:22:49<1:17:44, 19.12s/it] 66%|######5   | 467/710 [2:23:09<1:18:18, 19.34s/it] 66%|######5   | 468/710 [2:23:26<1:15:47, 18.79s/it] 66%|######6   | 469/710 [2:23:46<1:16:20, 19.01s/it] 66%|######6   | 470/710 [2:24:04<1:15:07, 18.78s/it]                                                      66%|######6   | 470/710 [2:24:04<1:15:07, 18.78s/it] 66%|######6   | 471/710 [2:24:24<1:16:12, 19.13s/it] 66%|######6   | 472/710 [2:24:44<1:17:13, 19.47s/it] 67%|######6   | 473/710 [2:25:03<1:16:41, 19.42s/it] 67%|######6   | 474/710 [2:25:22<1:14:56, 19.05s/it] 67%|######6   | 475/710 [2:25:40<1:14:12, 18.94s/it] 67%|######7   | 476/710 [2:25:59<1:13:14, 18.78s/it] 67%|######7   | 477/710 [2:26:17<1:11:48, 18.49s/it] 67%|######7   | 478/710 [2:26:35<1:11:36, 18.52s/it] 67%|######7   | 479/710 [2:26:54<1:11:14, 18.50s/it] 68%|######7   | 480/710 [2:27:13<1:12:30, 18.92s/it]                                                      68%|######7   | 480/710 [2:27:13<1:12:30, 18.92s/it] 68%|######7   | 481/710 [2:27:34<1:13:37, 19.29s/it] 68%|######7   | 482/710 [2:27:53<1:13:50, 19.43s/it] 68%|######8   | 483/710 [2:28:13<1:13:37, 19.46s/it] 68%|######8   | 484/710 [2:28:32<1:12:25, 19.23s/it] 68%|######8   | 485/710 [2:28:50<1:11:06, 18.96s/it] 68%|######8   | 486/710 [2:29:10<1:11:29, 19.15s/it] 69%|######8   | 487/710 [2:29:28<1:10:48, 19.05s/it] 69%|######8   | 488/710 [2:29:48<1:10:53, 19.16s/it] 69%|######8   | 489/710 [2:30:06<1:09:46, 18.94s/it] 69%|######9   | 490/710 [2:30:24<1:08:12, 18.60s/it]                                                      69%|######9   | 490/710 [2:30:24<1:08:12, 18.60s/it] 69%|######9   | 491/710 [2:30:42<1:07:38, 18.53s/it] 69%|######9   | 492/710 [2:31:00<1:06:18, 18.25s/it] 69%|######9   | 493/710 [2:31:18<1:05:45, 18.18s/it] 70%|######9   | 494/710 [2:31:37<1:06:08, 18.37s/it] 70%|######9   | 495/710 [2:31:56<1:06:39, 18.60s/it] 70%|######9   | 496/710 [2:32:14<1:06:08, 18.54s/it] 70%|#######   | 497/710 [2:32:34<1:07:03, 18.89s/it] 70%|#######   | 498/710 [2:32:53<1:06:32, 18.83s/it] 70%|#######   | 499/710 [2:33:13<1:07:14, 19.12s/it] 70%|#######   | 500/710 [2:33:31<1:06:39, 19.05s/it]                                                      70%|#######   | 500/710 [2:33:31<1:06:39, 19.05s/it] 71%|#######   | 501/710 [2:33:51<1:06:26, 19.07s/it] 71%|#######   | 502/710 [2:34:09<1:05:40, 18.95s/it] 71%|#######   | 503/710 [2:34:28<1:05:20, 18.94s/it] 71%|#######   | 504/710 [2:34:47<1:05:26, 19.06s/it] 71%|#######1  | 505/710 [2:35:06<1:04:48, 18.97s/it] 71%|#######1  | 506/710 [2:35:25<1:04:29, 18.97s/it] 71%|#######1  | 507/710 [2:35:45<1:04:58, 19.20s/it] 72%|#######1  | 508/710 [2:36:04<1:04:34, 19.18s/it] 72%|#######1  | 509/710 [2:36:22<1:03:06, 18.84s/it] 72%|#######1  | 510/710 [2:36:41<1:02:39, 18.80s/it]                                                      72%|#######1  | 510/710 [2:36:41<1:02:39, 18.80s/it] 72%|#######1  | 511/710 [2:36:59<1:01:56, 18.67s/it] 72%|#######2  | 512/710 [2:37:17<1:00:25, 18.31s/it] 72%|#######2  | 513/710 [2:37:35<1:00:31, 18.44s/it] 72%|#######2  | 514/710 [2:37:53<59:18, 18.15s/it]   73%|#######2  | 515/710 [2:38:13<1:00:46, 18.70s/it] 73%|#######2  | 516/710 [2:38:32<1:00:41, 18.77s/it] 73%|#######2  | 517/710 [2:38:52<1:01:26, 19.10s/it] 73%|#######2  | 518/710 [2:39:12<1:02:17, 19.47s/it] 73%|#######3  | 519/710 [2:39:32<1:02:47, 19.73s/it] 73%|#######3  | 520/710 [2:39:51<1:01:46, 19.51s/it]                                                      73%|#######3  | 520/710 [2:39:51<1:01:46, 19.51s/it] 73%|#######3  | 521/710 [2:40:11<1:01:21, 19.48s/it] 74%|#######3  | 522/710 [2:40:30<1:00:49, 19.41s/it] 74%|#######3  | 523/710 [2:40:49<1:00:03, 19.27s/it] 74%|#######3  | 524/710 [2:41:08<59:57, 19.34s/it]   74%|#######3  | 525/710 [2:41:28<1:00:09, 19.51s/it] 74%|#######4  | 526/710 [2:41:48<1:00:06, 19.60s/it] 74%|#######4  | 527/710 [2:42:07<59:29, 19.51s/it]   74%|#######4  | 528/710 [2:42:26<58:39, 19.34s/it] 75%|#######4  | 529/710 [2:42:46<58:33, 19.41s/it] 75%|#######4  | 530/710 [2:43:05<57:55, 19.31s/it]                                                    75%|#######4  | 530/710 [2:43:05<57:55, 19.31s/it] 75%|#######4  | 531/710 [2:43:24<57:03, 19.13s/it] 75%|#######4  | 532/710 [2:43:43<56:37, 19.09s/it] 75%|#######5  | 533/710 [2:44:01<55:48, 18.92s/it] 75%|#######5  | 534/710 [2:44:21<56:24, 19.23s/it] 75%|#######5  | 535/710 [2:44:39<54:52, 18.82s/it] 75%|#######5  | 536/710 [2:44:58<54:55, 18.94s/it] 76%|#######5  | 537/710 [2:45:18<54:54, 19.04s/it] 76%|#######5  | 538/710 [2:45:36<53:49, 18.77s/it] 76%|#######5  | 539/710 [2:45:54<53:22, 18.73s/it] 76%|#######6  | 540/710 [2:46:13<53:09, 18.76s/it]                                                    76%|#######6  | 540/710 [2:46:13<53:09, 18.76s/it] 76%|#######6  | 541/710 [2:46:32<53:13, 18.90s/it] 76%|#######6  | 542/710 [2:46:51<53:02, 18.94s/it] 76%|#######6  | 543/710 [2:47:11<52:54, 19.01s/it] 77%|#######6  | 544/710 [2:47:29<52:28, 18.97s/it] 77%|#######6  | 545/710 [2:47:48<51:52, 18.86s/it] 77%|#######6  | 546/710 [2:48:07<51:49, 18.96s/it] 77%|#######7  | 547/710 [2:48:26<51:36, 19.00s/it] 77%|#######7  | 548/710 [2:48:45<51:09, 18.95s/it] 77%|#######7  | 549/710 [2:49:04<50:34, 18.85s/it] 77%|#######7  | 550/710 [2:49:23<50:28, 18.93s/it]                                                    77%|#######7  | 550/710 [2:49:23<50:28, 18.93s/it] 78%|#######7  | 551/710 [2:49:41<49:50, 18.81s/it] 78%|#######7  | 552/710 [2:50:01<50:08, 19.04s/it] 78%|#######7  | 553/710 [2:50:20<50:07, 19.16s/it] 78%|#######8  | 554/710 [2:50:39<49:17, 18.96s/it] 78%|#######8  | 555/710 [2:50:59<49:55, 19.33s/it] 78%|#######8  | 556/710 [2:51:20<50:41, 19.75s/it] 78%|#######8  | 557/710 [2:51:39<50:04, 19.64s/it] 79%|#######8  | 558/710 [2:51:58<48:58, 19.33s/it] 79%|#######8  | 559/710 [2:52:17<48:06, 19.12s/it] 79%|#######8  | 560/710 [2:52:36<48:22, 19.35s/it]                                                    79%|#######8  | 560/710 [2:52:36<48:22, 19.35s/it] 79%|#######9  | 561/710 [2:52:54<46:52, 18.88s/it] 79%|#######9  | 562/710 [2:53:15<47:46, 19.37s/it] 79%|#######9  | 563/710 [2:53:35<47:55, 19.56s/it] 79%|#######9  | 564/710 [2:53:53<46:56, 19.29s/it] 80%|#######9  | 565/710 [2:54:13<46:42, 19.32s/it] 80%|#######9  | 566/710 [2:54:31<45:37, 19.01s/it] 80%|#######9  | 567/710 [2:54:50<45:07, 18.93s/it] 80%|########  | 568/710 [2:55:08<44:28, 18.79s/it] 80%|########  | 569/710 [2:55:26<43:44, 18.61s/it] 80%|########  | 570/710 [2:55:45<43:29, 18.64s/it]                                                    80%|########  | 570/710 [2:55:45<43:29, 18.64s/it] 80%|########  | 571/710 [2:56:04<43:29, 18.77s/it] 81%|########  | 572/710 [2:56:22<42:48, 18.61s/it] 81%|########  | 573/710 [2:56:41<42:27, 18.60s/it] 81%|########  | 574/710 [2:57:00<42:19, 18.67s/it] 81%|########  | 575/710 [2:57:18<41:42, 18.54s/it] 81%|########1 | 576/710 [2:57:37<41:48, 18.72s/it] 81%|########1 | 577/710 [2:57:57<42:08, 19.01s/it] 81%|########1 | 578/710 [2:58:16<41:41, 18.95s/it] 82%|########1 | 579/710 [2:58:35<41:31, 19.02s/it] 82%|########1 | 580/710 [2:58:53<40:52, 18.86s/it]                                                    82%|########1 | 580/710 [2:58:53<40:52, 18.86s/it] 82%|########1 | 581/710 [2:59:12<40:39, 18.91s/it] 82%|########1 | 582/710 [2:59:32<40:30, 18.99s/it] 82%|########2 | 583/710 [2:59:51<40:32, 19.15s/it] 82%|########2 | 584/710 [3:00:11<40:38, 19.35s/it] 82%|########2 | 585/710 [3:00:30<40:25, 19.40s/it] 83%|########2 | 586/710 [3:00:48<38:59, 18.87s/it] 83%|########2 | 587/710 [3:01:08<39:03, 19.05s/it] 83%|########2 | 588/710 [3:01:26<38:36, 18.99s/it] 83%|########2 | 589/710 [3:01:45<38:09, 18.92s/it] 83%|########3 | 590/710 [3:02:04<38:02, 19.02s/it]                                                    83%|########3 | 590/710 [3:02:04<38:02, 19.02s/it] 83%|########3 | 591/710 [3:02:24<38:02, 19.18s/it] 83%|########3 | 592/710 [3:02:43<37:21, 19.00s/it] 84%|########3 | 593/710 [3:03:01<36:43, 18.83s/it] 84%|########3 | 594/710 [3:03:19<36:10, 18.71s/it] 84%|########3 | 595/710 [3:03:39<36:21, 18.97s/it] 84%|########3 | 596/710 [3:03:58<36:03, 18.98s/it] 84%|########4 | 597/710 [3:04:17<35:43, 18.97s/it] 84%|########4 | 598/710 [3:04:36<35:36, 19.07s/it] 84%|########4 | 599/710 [3:04:55<35:20, 19.10s/it] 85%|########4 | 600/710 [3:05:14<34:57, 19.07s/it]                                                    85%|########4 | 600/710 [3:05:14<34:57, 19.07s/it][INFO|trainer.py:4309] 2026-01-02 20:13:20,977 >> Saving model checkpoint to lora/output_l4_lora\checkpoint-600
[INFO|configuration_utils.py:763] 2026-01-02 20:13:20,989 >> loading configuration file C:/models/Llama-3.1-8B-Instruct\config.json
[INFO|configuration_utils.py:839] 2026-01-02 20:13:20,990 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:13:21,173 >> chat template saved in lora/output_l4_lora\checkpoint-600\chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:13:21,175 >> tokenizer config file saved in lora/output_l4_lora\checkpoint-600\tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:13:21,177 >> Special tokens file saved in lora/output_l4_lora\checkpoint-600\special_tokens_map.json
[INFO|trainer.py:4418] 2026-01-02 20:13:21,687 >> Deleting older checkpoint [lora\output_l4_lora\checkpoint-200] due to args.save_total_limit
 85%|########4 | 601/710 [3:05:35<35:16, 19.42s/it] 85%|########4 | 602/710 [3:05:53<34:20, 19.08s/it] 85%|########4 | 603/710 [3:06:11<33:26, 18.76s/it] 85%|########5 | 604/710 [3:06:30<33:19, 18.86s/it] 85%|########5 | 605/710 [3:06:49<32:58, 18.84s/it] 85%|########5 | 606/710 [3:07:07<32:10, 18.57s/it] 85%|########5 | 607/710 [3:07:26<32:22, 18.86s/it] 86%|########5 | 608/710 [3:07:46<32:25, 19.07s/it] 86%|########5 | 609/710 [3:08:04<31:44, 18.86s/it] 86%|########5 | 610/710 [3:08:22<30:48, 18.49s/it]                                                    86%|########5 | 610/710 [3:08:22<30:48, 18.49s/it] 86%|########6 | 611/710 [3:08:42<31:08, 18.88s/it] 86%|########6 | 612/710 [3:09:02<31:18, 19.17s/it] 86%|########6 | 613/710 [3:09:20<30:36, 18.93s/it] 86%|########6 | 614/710 [3:09:39<30:27, 19.03s/it] 87%|########6 | 615/710 [3:09:59<30:24, 19.20s/it] 87%|########6 | 616/710 [3:10:17<29:29, 18.83s/it] 87%|########6 | 617/710 [3:10:36<29:35, 19.09s/it] 87%|########7 | 618/710 [3:10:55<28:58, 18.89s/it] 87%|########7 | 619/710 [3:11:14<28:37, 18.88s/it] 87%|########7 | 620/710 [3:11:33<28:43, 19.15s/it]                                                    87%|########7 | 620/710 [3:11:33<28:43, 19.15s/it] 87%|########7 | 621/710 [3:11:52<28:06, 18.95s/it] 88%|########7 | 622/710 [3:12:12<28:10, 19.21s/it] 88%|########7 | 623/710 [3:12:30<27:36, 19.04s/it] 88%|########7 | 624/710 [3:12:49<27:13, 18.99s/it] 88%|########8 | 625/710 [3:13:09<27:09, 19.17s/it] 88%|########8 | 626/710 [3:13:29<27:11, 19.42s/it] 88%|########8 | 627/710 [3:13:47<26:26, 19.11s/it] 88%|########8 | 628/710 [3:14:08<26:43, 19.55s/it] 89%|########8 | 629/710 [3:14:27<26:10, 19.38s/it] 89%|########8 | 630/710 [3:14:47<25:58, 19.48s/it]                                                    89%|########8 | 630/710 [3:14:47<25:58, 19.48s/it] 89%|########8 | 631/710 [3:15:04<24:52, 18.90s/it] 89%|########9 | 632/710 [3:15:22<24:10, 18.60s/it] 89%|########9 | 633/710 [3:15:40<23:38, 18.42s/it] 89%|########9 | 634/710 [3:15:59<23:34, 18.61s/it] 89%|########9 | 635/710 [3:16:18<23:15, 18.60s/it] 90%|########9 | 636/710 [3:16:37<23:15, 18.85s/it] 90%|########9 | 637/710 [3:16:57<23:11, 19.06s/it] 90%|########9 | 638/710 [3:17:15<22:28, 18.72s/it] 90%|######### | 639/710 [3:17:32<21:44, 18.37s/it] 90%|######### | 640/710 [3:17:52<21:58, 18.83s/it]                                                    90%|######### | 640/710 [3:17:52<21:58, 18.83s/it] 90%|######### | 641/710 [3:18:11<21:38, 18.82s/it] 90%|######### | 642/710 [3:18:29<21:12, 18.72s/it] 91%|######### | 643/710 [3:18:48<20:49, 18.65s/it] 91%|######### | 644/710 [3:19:08<20:52, 18.98s/it] 91%|######### | 645/710 [3:19:26<20:32, 18.96s/it] 91%|######### | 646/710 [3:19:45<20:04, 18.82s/it] 91%|#########1| 647/710 [3:20:03<19:24, 18.49s/it] 91%|#########1| 648/710 [3:20:22<19:18, 18.69s/it] 91%|#########1| 649/710 [3:20:40<18:59, 18.68s/it] 92%|#########1| 650/710 [3:20:57<18:07, 18.13s/it]                                                    92%|#########1| 650/710 [3:20:57<18:07, 18.13s/it] 92%|#########1| 651/710 [3:21:14<17:30, 17.81s/it] 92%|#########1| 652/710 [3:21:34<17:47, 18.40s/it] 92%|#########1| 653/710 [3:21:52<17:26, 18.37s/it] 92%|#########2| 654/710 [3:22:10<16:56, 18.16s/it] 92%|#########2| 655/710 [3:22:28<16:27, 17.96s/it] 92%|#########2| 656/710 [3:22:47<16:25, 18.24s/it] 93%|#########2| 657/710 [3:23:05<16:06, 18.24s/it] 93%|#########2| 658/710 [3:23:24<16:02, 18.51s/it] 93%|#########2| 659/710 [3:23:43<15:49, 18.61s/it] 93%|#########2| 660/710 [3:24:01<15:31, 18.62s/it]                                                    93%|#########2| 660/710 [3:24:01<15:31, 18.62s/it] 93%|#########3| 661/710 [3:24:19<14:52, 18.21s/it] 93%|#########3| 662/710 [3:24:38<14:49, 18.53s/it] 93%|#########3| 663/710 [3:24:55<14:12, 18.13s/it] 94%|#########3| 664/710 [3:25:14<14:00, 18.28s/it] 94%|#########3| 665/710 [3:25:33<13:53, 18.51s/it] 94%|#########3| 666/710 [3:25:50<13:17, 18.12s/it] 94%|#########3| 667/710 [3:26:07<12:46, 17.82s/it] 94%|#########4| 668/710 [3:26:26<12:37, 18.05s/it] 94%|#########4| 669/710 [3:26:44<12:27, 18.24s/it] 94%|#########4| 670/710 [3:27:02<12:03, 18.08s/it]                                                    94%|#########4| 670/710 [3:27:02<12:03, 18.08s/it] 95%|#########4| 671/710 [3:27:21<11:56, 18.37s/it] 95%|#########4| 672/710 [3:27:40<11:39, 18.41s/it] 95%|#########4| 673/710 [3:27:58<11:16, 18.30s/it] 95%|#########4| 674/710 [3:28:16<10:59, 18.32s/it] 95%|#########5| 675/710 [3:28:34<10:38, 18.23s/it] 95%|#########5| 676/710 [3:28:52<10:20, 18.25s/it] 95%|#########5| 677/710 [3:29:09<09:47, 17.80s/it] 95%|#########5| 678/710 [3:29:27<09:33, 17.92s/it] 96%|#########5| 679/710 [3:29:46<09:24, 18.22s/it] 96%|#########5| 680/710 [3:30:04<09:00, 18.01s/it]                                                    96%|#########5| 680/710 [3:30:04<09:00, 18.01s/it] 96%|#########5| 681/710 [3:30:23<08:50, 18.30s/it] 96%|#########6| 682/710 [3:30:41<08:31, 18.27s/it] 96%|#########6| 683/710 [3:30:59<08:10, 18.17s/it] 96%|#########6| 684/710 [3:31:17<07:52, 18.18s/it] 96%|#########6| 685/710 [3:31:35<07:28, 17.96s/it] 97%|#########6| 686/710 [3:31:53<07:12, 18.02s/it] 97%|#########6| 687/710 [3:32:11<06:59, 18.26s/it] 97%|#########6| 688/710 [3:32:30<06:40, 18.22s/it] 97%|#########7| 689/710 [3:32:48<06:26, 18.40s/it] 97%|#########7| 690/710 [3:33:07<06:07, 18.37s/it]                                                    97%|#########7| 690/710 [3:33:07<06:07, 18.37s/it] 97%|#########7| 691/710 [3:33:25<05:46, 18.25s/it] 97%|#########7| 692/710 [3:33:43<05:27, 18.20s/it] 98%|#########7| 693/710 [3:34:01<05:07, 18.09s/it] 98%|#########7| 694/710 [3:34:18<04:47, 18.00s/it] 98%|#########7| 695/710 [3:34:37<04:33, 18.24s/it] 98%|#########8| 696/710 [3:34:56<04:15, 18.28s/it] 98%|#########8| 697/710 [3:35:15<04:00, 18.48s/it] 98%|#########8| 698/710 [3:35:33<03:43, 18.60s/it] 98%|#########8| 699/710 [3:35:52<03:25, 18.71s/it] 99%|#########8| 700/710 [3:36:11<03:06, 18.61s/it]                                                    99%|#########8| 700/710 [3:36:11<03:06, 18.61s/it] 99%|#########8| 701/710 [3:36:27<02:41, 17.92s/it] 99%|#########8| 702/710 [3:36:46<02:25, 18.18s/it] 99%|#########9| 703/710 [3:37:04<02:07, 18.26s/it] 99%|#########9| 704/710 [3:37:24<01:51, 18.61s/it] 99%|#########9| 705/710 [3:37:42<01:32, 18.54s/it] 99%|#########9| 706/710 [3:38:01<01:14, 18.54s/it]100%|#########9| 707/710 [3:38:20<00:56, 18.68s/it]100%|#########9| 708/710 [3:38:36<00:36, 18.06s/it]100%|#########9| 709/710 [3:38:53<00:17, 17.77s/it]100%|##########| 710/710 [3:39:03<00:00, 15.30s/it]                                                   100%|##########| 710/710 [3:39:03<00:00, 15.30s/it][INFO|trainer.py:4309] 2026-01-02 20:47:09,418 >> Saving model checkpoint to lora/output_l4_lora\checkpoint-710
[INFO|configuration_utils.py:763] 2026-01-02 20:47:09,431 >> loading configuration file C:/models/Llama-3.1-8B-Instruct\config.json
[INFO|configuration_utils.py:839] 2026-01-02 20:47:09,432 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:47:09,621 >> chat template saved in lora/output_l4_lora\checkpoint-710\chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:47:09,623 >> tokenizer config file saved in lora/output_l4_lora\checkpoint-710\tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:47:09,625 >> Special tokens file saved in lora/output_l4_lora\checkpoint-710\special_tokens_map.json
[INFO|trainer.py:4418] 2026-01-02 20:47:10,180 >> Deleting older checkpoint [lora\output_l4_lora\checkpoint-400] due to args.save_total_limit
[INFO|trainer.py:2810] 2026-01-02 20:47:10,184 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|##########| 710/710 [3:39:04<00:00, 15.30s/it]100%|##########| 710/710 [3:39:04<00:00, 18.51s/it]
[INFO|trainer.py:4309] 2026-01-02 20:47:10,186 >> Saving model checkpoint to lora/output_l4_lora
[INFO|configuration_utils.py:763] 2026-01-02 20:47:10,201 >> loading configuration file C:/models/Llama-3.1-8B-Instruct\config.json
[INFO|configuration_utils.py:839] 2026-01-02 20:47:10,202 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "use_cache": true,
  "vocab_size": 128256
}

[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:47:10,479 >> chat template saved in lora/output_l4_lora\chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:47:10,483 >> tokenizer config file saved in lora/output_l4_lora\tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:47:10,483 >> Special tokens file saved in lora/output_l4_lora\special_tokens_map.json
[INFO|trainer.py:4643] 2026-01-02 20:47:10,623 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2026-01-02 20:47:10,624 >>   Num examples = 630
[INFO|trainer.py:4648] 2026-01-02 20:47:10,624 >>   Batch size = 8
  0%|          | 0/79 [00:00<?, ?it/s]  3%|2         | 2/79 [00:02<01:54,  1.49s/it]  4%|3         | 3/79 [00:05<02:41,  2.12s/it]  5%|5         | 4/79 [00:09<03:04,  2.46s/it]  6%|6         | 5/79 [00:12<03:15,  2.65s/it]  8%|7         | 6/79 [00:14<03:20,  2.75s/it]  9%|8         | 7/79 [00:17<03:22,  2.81s/it] 10%|#         | 8/79 [00:20<03:21,  2.84s/it] 11%|#1        | 9/79 [00:23<03:20,  2.87s/it] 13%|#2        | 10/79 [00:26<03:20,  2.91s/it] 14%|#3        | 11/79 [00:29<03:19,  2.94s/it] 15%|#5        | 12/79 [00:32<03:16,  2.94s/it] 16%|#6        | 13/79 [00:35<03:13,  2.93s/it] 18%|#7        | 14/79 [00:38<03:09,  2.92s/it] 19%|#8        | 15/79 [00:41<03:06,  2.91s/it] 20%|##        | 16/79 [00:44<03:02,  2.90s/it] 22%|##1       | 17/79 [00:47<02:59,  2.90s/it] 23%|##2       | 18/79 [00:50<02:56,  2.90s/it] 24%|##4       | 19/79 [01:12<08:50,  8.85s/it] 25%|##5       | 20/79 [01:15<06:56,  7.06s/it] 27%|##6       | 21/79 [01:18<05:36,  5.81s/it] 28%|##7       | 22/79 [01:21<04:41,  4.93s/it] 29%|##9       | 23/79 [01:24<04:02,  4.32s/it] 30%|###       | 24/79 [01:47<09:06,  9.93s/it] 32%|###1      | 25/79 [01:50<07:03,  7.85s/it] 33%|###2      | 26/79 [01:53<05:38,  6.39s/it] 34%|###4      | 27/79 [01:56<04:39,  5.37s/it] 35%|###5      | 28/79 [01:59<03:57,  4.66s/it] 37%|###6      | 29/79 [02:02<03:27,  4.16s/it] 38%|###7      | 30/79 [02:05<03:06,  3.81s/it] 39%|###9      | 31/79 [02:08<02:50,  3.56s/it] 41%|####      | 32/79 [02:11<02:39,  3.39s/it] 42%|####1     | 33/79 [02:14<02:30,  3.27s/it] 43%|####3     | 34/79 [02:17<02:23,  3.19s/it] 44%|####4     | 35/79 [02:20<02:17,  3.13s/it] 46%|####5     | 36/79 [02:23<02:13,  3.10s/it] 47%|####6     | 37/79 [03:07<10:48, 15.44s/it] 48%|####8     | 38/79 [03:13<08:33, 12.53s/it] 49%|####9     | 39/79 [03:18<06:59, 10.48s/it] 51%|#####     | 40/79 [03:24<05:53,  9.07s/it] 52%|#####1    | 41/79 [03:30<05:07,  8.08s/it] 53%|#####3    | 42/79 [04:13<11:24, 18.51s/it] 54%|#####4    | 43/79 [04:50<14:29, 24.15s/it] 56%|#####5    | 44/79 [04:54<10:27, 17.92s/it] 57%|#####6    | 45/79 [04:57<07:38, 13.47s/it] 58%|#####8    | 46/79 [05:00<05:41, 10.34s/it] 59%|#####9    | 47/79 [05:03<04:22,  8.19s/it] 61%|######    | 48/79 [05:06<03:26,  6.65s/it] 62%|######2   | 49/79 [05:09<02:47,  5.60s/it] 63%|######3   | 50/79 [05:12<02:18,  4.78s/it] 65%|######4   | 51/79 [05:16<02:10,  4.66s/it] 66%|######5   | 52/79 [05:20<01:58,  4.39s/it] 67%|######7   | 53/79 [05:24<01:48,  4.19s/it] 68%|######8   | 54/79 [05:52<04:44, 11.36s/it] 70%|######9   | 55/79 [06:20<06:33, 16.40s/it] 71%|#######   | 56/79 [06:24<04:49, 12.61s/it] 72%|#######2  | 57/79 [06:27<03:38,  9.93s/it] 73%|#######3  | 58/79 [06:31<02:49,  8.07s/it] 75%|#######4  | 59/79 [06:35<02:15,  6.78s/it] 76%|#######5  | 60/79 [07:03<04:11, 13.22s/it] 77%|#######7  | 61/79 [07:09<03:17, 10.95s/it] 78%|#######8  | 62/79 [07:16<02:44,  9.65s/it] 80%|#######9  | 63/79 [07:21<02:12,  8.28s/it] 81%|########1 | 64/79 [07:24<01:43,  6.92s/it] 82%|########2 | 65/79 [07:30<01:32,  6.63s/it] 84%|########3 | 66/79 [08:03<03:07, 14.39s/it] 85%|########4 | 67/79 [08:07<02:14, 11.20s/it] 86%|########6 | 68/79 [08:10<01:38,  8.96s/it] 87%|########7 | 69/79 [08:14<01:13,  7.39s/it] 89%|########8 | 70/79 [08:41<02:00, 13.41s/it] 90%|########9 | 71/79 [08:45<01:24, 10.53s/it] 91%|#########1| 72/79 [08:49<00:59,  8.51s/it] 92%|#########2| 73/79 [08:53<00:42,  7.08s/it] 94%|#########3| 74/79 [08:57<00:30,  6.09s/it] 95%|#########4| 75/79 [09:00<00:21,  5.39s/it] 96%|#########6| 76/79 [09:28<00:36, 12.09s/it] 97%|#########7| 77/79 [09:32<00:19,  9.59s/it] 99%|#########8| 78/79 [09:36<00:07,  7.84s/it]100%|##########| 79/79 [09:38<00:00,  6.33s/it]100%|##########| 79/79 [09:38<00:00,  7.33s/it]
[INFO|modelcard.py:456] 2026-01-02 20:56:53,344 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
